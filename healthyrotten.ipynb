{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU/za7N0IqJ3vbiIW7ps4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bziukiewicz/tests/blob/main/healthyrotten.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "GUYqpZCXHzZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zmienna `path` zawiera ścieżkę, którą zwraca kagglehub\n",
        "# Skopiuj dane do /content/dataset\n",
        "shutil.copytree(path, \"/content/dataset\", dirs_exist_ok=True)\n"
      ],
      "metadata": {
        "id": "qUyBp8UrH_U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "ezD-YpP-I796"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./images"
      ],
      "metadata": {
        "id": "A6Sl8MXHKV98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir='./dataset/Fruit And Vegetable Diseases Dataset'\n",
        "data_dir='./images'\n",
        "if not os.path.exists(data_dir):\n",
        "  os.mkdir(data_dir)\n",
        "train_dir=os.path.join(data_dir,'train')\n",
        "valid_dir=os.path.join(data_dir,'valid')\n",
        "test_dir=os.path.join(data_dir,'test')\n",
        "train_healthy_dir=os.path.join(train_dir,'healthyapple')\n",
        "train_rotten_dir=os.path.join(train_dir,'rottenapple')\n",
        "valid_healthy_dir=os.path.join(valid_dir,'healthyapple')\n",
        "valid_rotten_dir=os.path.join(valid_dir,'rottenapple')\n",
        "test_healthy_dir=os.path.join(test_dir,'healthyapple')\n",
        "test_rotten_dir=os.path.join(test_dir,'rottenapple')\n",
        "\n",
        "for directory in (train_dir,valid_dir,test_dir):\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in (train_healthy_dir,train_rotten_dir,valid_healthy_dir,valid_rotten_dir,test_healthy_dir,test_rotten_dir):\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n"
      ],
      "metadata": {
        "id": "AH9_rnwZUcqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_fnames=os.listdir(os.path.join(base_dir,'Apple__Healthy'))\n",
        "rotten_fnames=os.listdir(os.path.join(base_dir,'Apple__Rotten'))\n",
        "\n",
        "healthy_fnames=[fname for fname in healthy_fnames if fname.split('.')[1].lower() in ['jpg','jpeg','png']]\n",
        "rotten_fnames=[fname for fname in rotten_fnames if fname.split('.')[1].lower() in ['jpg','jpeg','png']]"
      ],
      "metadata": {
        "id": "T_LXfu5TW4V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=min(len(rotten_fnames),len(healthy_fnames))\n",
        "train_size=int(np.floor(size*0.7))\n",
        "valid_size=int(np.floor(size*0.2))\n",
        "test_size=int(np.floor(size*0.1))\n",
        "train_idx=train_size\n",
        "valid_idx=train_idx+valid_size\n",
        "test_idx=valid_idx+test_size"
      ],
      "metadata": {
        "id": "6idcjMBPX2qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, fname in enumerate(healthy_fnames):\n",
        "  if i<=train_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Healthy', fname)\n",
        "    dst=os.path.join(train_healthy_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "  elif train_idx<i<=valid_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Healthy', fname)\n",
        "    dst=os.path.join(valid_healthy_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "  elif valid_idx<i<test_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Healthy', fname)\n",
        "    dst=os.path.join(test_healthy_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "\n",
        "for i, fname in enumerate(rotten_fnames):\n",
        "  if i<=train_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Rotten', fname)\n",
        "    dst=os.path.join(train_rotten_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "  elif train_idx<i<=valid_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Rotten', fname)\n",
        "    dst=os.path.join(valid_rotten_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "  elif valid_idx<i<test_idx:\n",
        "    src=os.path.join(base_dir,'Apple__Rotten', fname)\n",
        "    dst=os.path.join(test_rotten_dir, fname)\n",
        "    shutil.copyfile(src,dst)\n",
        "\n"
      ],
      "metadata": {
        "id": "i7ZFCXtFX9Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(train_rotten_dir))"
      ],
      "metadata": {
        "id": "Xf6un_xEaMIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    brightness_range=[0.5,2.0],\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1./255)\n",
        "valid_datagen=ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "valid_generator=valid_datagen.flow_from_directory(\n",
        "    directory=valid_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "bQ-jh96naz6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_augmented_images(directory, idx):\n",
        "    \"\"\"\n",
        "    Funkcja zwraca wykres przykładowych obrazów uzyskanych za pomocą techniki\n",
        "    augmentacji danych.\n",
        "    \"\"\"\n",
        "    fnames = [os.path.join(directory, fname) for fname in os.listdir(directory)]\n",
        "    img_path = fnames[idx]\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "    i = 1\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for batch in train_datagen.flow(x, batch_size=1):\n",
        "        plt.subplot(3, 4, i)\n",
        "        plt.grid(False)\n",
        "        imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "        i += 1\n",
        "        if i % 13 == 0:\n",
        "            break"
      ],
      "metadata": {
        "id": "XJDEQFZndT3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zbiór treningowy drone:\n",
        "idx = 17 #@param {type:'slider', min:0, max:409}\n",
        "display_augmented_images(train_rotten_dir, idx)"
      ],
      "metadata": {
        "id": "O9AlbmN0dquu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,'relu'))\n",
        "model.add(layers.Dense(1,'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6CY0kVX4drGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('rmsprop','binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0AwHS2oje-AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "steps_per_epoch=train_size//batch_size\n",
        "validation_steps=valid_size//batch_size\n",
        "\n",
        "history=model.fit(x=train_generator,\n",
        "                  steps_per_epoch=steps_per_epoch,\n",
        "                  epochs=40,\n",
        "                  validation_data=valid_generator,\n",
        "                  validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "AnKzmW81fiSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363d18d5-883e-4a25-df9b-51d1f5f40e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.5196 - loss: 0.9695 - val_accuracy: 0.5000 - val_loss: 0.7214\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.5087 - loss: 0.7095 - val_accuracy: 0.3542 - val_loss: 0.6889\n",
            "Epoch 3/40\n",
            "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6951"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 639ms/step - accuracy: 0.5521 - loss: 0.6945 - val_accuracy: 0.4792 - val_loss: 0.6882\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.4842 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6824\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.5718 - loss: 0.6954 - val_accuracy: 0.7500 - val_loss: 0.6627\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 801ms/step - accuracy: 0.5046 - loss: 0.6958 - val_accuracy: 0.6875 - val_loss: 0.6760\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.5790 - loss: 0.6980 - val_accuracy: 0.7396 - val_loss: 0.6385\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6497 - loss: 0.6641 - val_accuracy: 0.6354 - val_loss: 0.6757\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.5339 - loss: 0.7195 - val_accuracy: 0.5417 - val_loss: 0.6703\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.5896 - loss: 0.6668 - val_accuracy: 0.6875 - val_loss: 0.6078\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.5871 - loss: 0.7394 - val_accuracy: 0.6458 - val_loss: 0.6386\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5391 - loss: 0.7144 - val_accuracy: 0.4375 - val_loss: 0.7645\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.6293 - loss: 0.6480 - val_accuracy: 0.7396 - val_loss: 0.5242\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.6825 - loss: 0.5987 - val_accuracy: 0.7083 - val_loss: 0.5620\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 472ms/step - accuracy: 0.7500 - loss: 0.5092 - val_accuracy: 0.6875 - val_loss: 0.5354\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.6784 - loss: 0.6017 - val_accuracy: 0.7812 - val_loss: 0.4656\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.6345 - loss: 0.6247 - val_accuracy: 0.7083 - val_loss: 0.5261\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 659ms/step - accuracy: 0.7500 - loss: 0.5807 - val_accuracy: 0.7604 - val_loss: 0.5177\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.7261 - loss: 0.5298 - val_accuracy: 0.7292 - val_loss: 0.5402\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6956 - loss: 0.5499 - val_accuracy: 0.6146 - val_loss: 0.9716\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 736ms/step - accuracy: 0.6276 - loss: 0.6674 - val_accuracy: 0.7500 - val_loss: 0.5237\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - accuracy: 0.7114 - loss: 0.5530 - val_accuracy: 0.7292 - val_loss: 0.4963\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.7810 - loss: 0.4722 - val_accuracy: 0.8021 - val_loss: 0.4644\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 670ms/step - accuracy: 0.7669 - loss: 0.6074 - val_accuracy: 0.7917 - val_loss: 0.4425\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.8022 - loss: 0.4743 - val_accuracy: 0.8021 - val_loss: 0.4259\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.7580 - loss: 0.4758 - val_accuracy: 0.7917 - val_loss: 0.5665\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 728ms/step - accuracy: 0.7070 - loss: 0.4183 - val_accuracy: 0.6042 - val_loss: 0.5721\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.7321 - loss: 0.5068 - val_accuracy: 0.7604 - val_loss: 0.4370\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.7431 - loss: 0.4528 - val_accuracy: 0.8021 - val_loss: 0.4289\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 794ms/step - accuracy: 0.8257 - loss: 0.3956 - val_accuracy: 0.7396 - val_loss: 0.6265\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.7883 - loss: 0.4346 - val_accuracy: 0.6354 - val_loss: 0.5238\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.7415 - loss: 0.4800 - val_accuracy: 0.8125 - val_loss: 0.3844\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7044 - loss: 0.5406 - val_accuracy: 0.5833 - val_loss: 0.6743\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3s/step - accuracy: 0.6724 - loss: 0.6212 - val_accuracy: 0.8750 - val_loss: 0.3718\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.7641 - loss: 0.6140 - val_accuracy: 0.8438 - val_loss: 0.4285\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 626ms/step - accuracy: 0.7643 - loss: 0.4711 - val_accuracy: 0.8958 - val_loss: 0.3517\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8427 - loss: 0.3686"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hist(history):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['accuracy'], name='accuracy', mode='markers+lines'))\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_accuracy'], name='val_accuracy', mode='markers+lines'))\n",
        "    fig.update_layout(width=1000, height=500, title='Accuracy vs. Val Accuracy', xaxis_title='Epoki', yaxis_title='Accuracy', yaxis_type='log')\n",
        "    fig.show()\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['loss'], name='loss', mode='markers+lines'))\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_loss'], name='val_loss', mode='markers+lines'))\n",
        "    fig.update_layout(width=1000, height=500, title='Loss vs. Val Loss', xaxis_title='Epoki', yaxis_title='Loss', yaxis_type='log')\n",
        "    fig.show()\n",
        "\n",
        "plot_hist(history)"
      ],
      "metadata": {
        "id": "pHvJMLoMhhSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "y_prob = model.predict(test_generator, test_generator.samples)\n",
        "y_prob = y_prob.ravel()\n",
        "y_prob"
      ],
      "metadata": {
        "id": "Pca7VYO0lnWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions  = pd.DataFrame({'y_prob': y_prob})\n",
        "predictions['class'] = predictions['y_prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "predictions"
      ],
      "metadata": {
        "id": "aZpTfOd2l2tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_generator.classes\n",
        "y_true"
      ],
      "metadata": {
        "id": "jnNit2hjl6dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predictions['class'].values\n",
        "y_pred"
      ],
      "metadata": {
        "id": "VppNFeG-l6wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator.class_indices"
      ],
      "metadata": {
        "id": "U0zEl9VNl-vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "A5UrYAGNmBrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred}, index=test_generator.filenames)\n",
        "errors.head()"
      ],
      "metadata": {
        "id": "Oqa9mx0umFKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors['is_incorrect'] = (errors['y_true'] != errors['y_pred']) * 1\n",
        "errors"
      ],
      "metadata": {
        "id": "TlOCMYW5mKc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors[errors['is_incorrect'] == 1].index"
      ],
      "metadata": {
        "id": "KQ5QO-VcmMK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = os.path.join(test_rotten_dir, 'rottenApple (87).jpg')\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "UpVsBNcAmOYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_z6ZH4sUmkRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}